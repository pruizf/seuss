{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See https://spacy.io/usage/spacy-101 for an intro\n",
    "- Site also has recipes for different tasks (sentiment etc.)\n",
    "- https://spacy.io/usage/facts-figures \n",
    "\n",
    "\n",
    "- Spanish and German models\n",
    "- Easy to try (a pipeline including dependency parsing takes three lines of code)\n",
    "- Classical pipeline and neural NLP components. Word embeddings available from the outset\n",
    "\n",
    "\n",
    "- No coreference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Several package managers supportd (pip, conda) or also with OS package manager\n",
    "\n",
    "- Download the language modules after installation, e.g for Spanish  `python -m spacy download es`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ES\n",
      "\n",
      "El\tEl\tDET__Definite=Def|Gender=Masc|Number=Sing|PronType=Art\t \tDET\tdet\n",
      "hombre\thombre\tNOUN__Gender=Masc|Number=Sing\t                          \tNOUN\tnsubj\n",
      "bajo\tbajar\tADJ__Gender=Masc|Number=Sing\t                           \tADJ\tmark\n",
      "toca\ttocar\tVERB__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t\tVERB\tROOT\n",
      "un\tuno\tDET__Definite=Ind|Gender=Masc|Number=Sing|PronType=Art\t \tDET\tdet\n",
      "bajo\tbajar\tNOUN__Gender=Masc|Number=Sing\t                          \tNOUN\tobj\n",
      "bajo\tbajar\tADP__AdpType=Prep\t                                      \tADP\tcase\n",
      "el\tel\tDET__Definite=Def|Gender=Masc|Number=Sing|PronType=Art\t \tDET\tdet\n",
      "baobab\tbaobab\tNOUN__Gender=Masc|Number=Sing\t                          \tNOUN\tnmod\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"es\")\n",
    "print(\"Loaded ES\\n\")\n",
    "doc = nlp(\"El hombre bajo toca un bajo bajo el baobab\")\n",
    "for word in doc:\n",
    "    print(word.text, word.lemma_, word.tag_, \" \"* (55-len(word.tag_)), word.pos_, word.dep_, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caín PER 3 4\n",
      "Juan PER 22 23\n",
      "Martín PER 24 25\n",
      " de Alvargonzález PER 28 31\n",
      "Duero LOC 43 44\n",
      "Laguna Negra LOC 53 55\n"
     ]
    }
   ],
   "source": [
    "txt = \"\"\"Mucha sangre de Caín\n",
    "tiene la gente labriega, \n",
    "y en el hogar campesino \n",
    "armó la envidia pelea.\n",
    "\n",
    "Juan y Martín, los mayores \n",
    "de Alvargonzález, un día \n",
    "pesada marcha emprendieron \n",
    "con el alba, Duero arriba.\n",
    "\n",
    "Llegaron los asesinos \n",
    "hasta la Laguna Negra, \n",
    "agua transparente y muda \n",
    "que enorme muro de piedra\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(txt.replace(\"\\n\", \" \"))\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_, ent.start, ent.end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching sequences (Rule-based matching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://spacy.io/usage/linguistic-features#rule-based-matching\n",
    "\n",
    "\n",
    "Here the task is to match phrases where an adjective is predicated on \"Facebook\" using a sequence of tokens and the spacy `Matcher` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ents': [{'label': 'MATCH', 'end': 27, 'start': 0}], 'text': 'Facebook is really horrible and FAcebook is very bad'}, {'ents': [{'label': 'MATCH', 'end': 52, 'start': 32}], 'text': 'Facebook is really horrible and FAcebook is very bad'}]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matched_sents = [] # collect data of matched sentences to be visualized\n",
    "\n",
    "def collect_sents(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    span = doc[start : end] # matched span\n",
    "    sent = span.sent # sentence containing matched span\n",
    "    # append mock entity for match in displaCy style to matched_sents\n",
    "    # get the match span by ofsetting the start and end of the span with the\n",
    "    # start and end of the sentence in the doc\n",
    "    match_ents = [{'start': span.start_char - sent.start_char,\n",
    "                   'end': span.end_char - sent.start_char,\n",
    "                   'label': 'MATCH'}]\n",
    "    matched_sents.append({'text': sent.text, 'ents': match_ents })\n",
    "\n",
    "pattern = [{'LOWER': 'facebook'}, {'LEMMA': 'be'}, {'POS': 'ADV', 'OP': '*'},\n",
    "           {'POS': 'ADJ'}]\n",
    "matcher.add('FacebookIs', collect_sents, pattern) # add pattern\n",
    "matches = matcher(nlp(\"Facebook is really horrible and FAcebook is very bad\")) # match on your text\n",
    "\n",
    "print(matched_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If want to visualize the matches, can use displacy (shows results on localhost:5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Serving on port 5000...\u001b[0m\n",
      "    Using the 'ent' visualizer\n",
      "\n",
      "\n",
      "    Shutting down server on port 5000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# serve visualization of sentences containing match with displaCy\n",
    "# set manual=True to make displaCy render straight from a dictionary\n",
    "displacy.serve(matched_sents, style='ent', manual=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write rules for identifying novel metadata with the `Matcher` (or perhapss the `PhraseMatcher`) classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
